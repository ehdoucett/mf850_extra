# Get the variables from backward selection
# Split categorical variables into seperate columns
x = model.matrix(CRED_APPROVED~., data = train)
# Re structure data so the data so it is a data frame and not a matrix
data3 <- data.frame(x)
# Save names of the coefficients in the backward step wise regression
coef_names <- names(backwards$coefficients)
# Delete the first name which is X intercept
coef_names <- coef_names[-1]
# Make sure all the variables are in the data set
data_col_names <- colnames(data3)
sum(coef_names%in% data_col_names) == (length(coef_names))
# Get the columns from the new data set
data_rf <- data3[,coef_names]
# Random forest with that data
library(randomForest)
fit_rf1 <- randomForest(CRED_APPROVED~. , data = data_rf)
fit_rf1
data_rf <- data[,c(CRED_APPROVED, coef_names)]
data_rf <- data[,cbind(CRED_APPROVED, coef_names)]
data_rf <- data[,rbind(CRED_APPROVED, coef_names)]
data_rf <- data[,c("CRED_APPROVED", coef_names)]
data_rf <- data[,rbind("CRED_APPROVED", coef_names)]
data_rf <- data[,cbind("CRED_APPROVED", coef_names)]
data_rf <- data[,coef_names]
# Split categorical variables into seperate columns
x = model.matrix(CRED_APPROVED~., data = train)
# Re structure data so the data so it is a data frame and not a matrix
data3 <- data.frame(x)
# Save names of the coefficients in the backward step wise regression
coef_names <- names(backwards$coefficients)
# Delete the first name which is X intercept
coef_names <- coef_names[-1]
# Make sure all the variables are in the data set
data_col_names <- colnames(data3)
sum(coef_names%in% data_col_names) == (length(coef_names))
# Get the columns from the new data set
data_rf <- data[,coef_names]
data_rf <- data3[,c("CRED_APPROVED",coef_names)]
data1 <- data3[,coef_names]
coef1 <- c("CRED_APPROVED",coef_names)
View(data3)
View(data3)
data_rf <- data3[,coef_names]
data1 <- cbind(data_rf, y)
fit_rf1 <- randomForest(CRED_APPROVED~. , data = data1)
fit_rf1 <- randomForest(y~. , data = data1)
fit_rf1
View(data1)
View(data1)
fit_rf1 <- randomForest(as.factor(y)~. , data = data1)
fit_rf1
summary(fit_rf1)
fit_rf1
importance(fit_rf1)
importance(fit_rf1)
fit_rf2 <- randomForest(as.factor(y)~. , data = data1)
fit_rf2
importance(fit_rf2)
?tuneRF
fit3 <- tuneRF(data_rf, as.factor(y))
?tuneRF
?randomForest
names(fit_rf2)
fit_rf2[7]
names(fit_rf2)
fit_rf2[4]
names(fit_rf2)
fit_rf2[5]
df1 <- data.frame()
df1[1] <- fit_rf2[5]
df1[1,2] <- fit_rf2[5]
df1[c(1,2),1] <- fit_rf2[5]
df1
df1[c(1,2),] <- fit_rf2[5]
df1
indexes <- sample(1:nrow(data), size = 0.2*nrow(data))
test <- data[indexes, ]
train <- data[-indexes, ]
library(randomForest)
set.seed(1)
fit_rf1 <- randomForest(CRED_APPROVED~. , data = train)
fit_rf1
importance(fit_rf1)
?predict.randomForest
predict_rf <- predict(fit_rf1, newdata= test)
hist(predict_rf)
predict_rf
predict_rf <- ifelse(predict_fit2 == 'YES',1 ,0)
hist(predict_rf)
misClasificError <- mean(predict_rf != test$CRED_APPROVED)
print(paste('Accuracy',1-misClasificError))
predict_rf <- predict(fit_rf1, newdata= test)
predict_rf <- ifelse(predict_rf == 'YES', 1,0)
misClasificError <- mean(predict_rf != test$CRED_APPROVED)
print(paste('Accuracy',1-misClasificError))
predict_rf
misClasificError <- mean(predict_rf != test$CRED_APPROVED)
print(paste('Accuracy',1-misClasificError))
test
predict_rf <- predict(fit_rf1, newdata= test)
misClasificError <- mean(predict_rf != test$CRED_APPROVED)
print(paste('Accuracy',1-misClasificError))
table(test$CRED_APPROVED, predict_fit2 == 'YES')
table(test$CRED_APPROVED, predict_fit2)
table(test$CRED_APPROVED, predict_fit2=='NO')
# Confusion matrix
table(test$CRED_APPROVED, predict_fit2>0.5)
table(test$CRED_APPROVED, predict_fit2=='NO')
table(test$CRED_APPROVED, predict_fit2=='YES')
library(caret)
install.packages("caret")
library(caret)
?confusionMatrix
confusionMatrix(predict_fit2, test$CRED_APPROVED)
table(data$CRED_APPROVED)/nrow(data$CRED_APPROVED)
table(data$CRED_APPROVED)/nrow(data)
setwd("C:/Users/board/Desktop/Kaggle/mf850_extra")
data <- read.csv("mf850-loan-data.csv")
# Some data cleaning
data$DEPENDENTS <- as.factor(data$DEPENDENTS)
data$CRED_HERE <- as.factor(data$CRED_HERE)
data$INSTALLMENTRATE <- as.factor(data$INSTALLMENTRATE)
data$ATADDRESSSINCE <- as.factor(data$ATADDRESSSINCE)
data$AGE <- scale(data$AGE)
data$DURATION <- scale(data$DURATION)
head(data)
summary(data)
# Sample split into test train set
indexes <- sample(1:nrow(data), size = 0.2*nrow(data))
test <- data[indexes, ]
train <- data[-indexes, ]
library(randomForest)
set.seed(1)
# Fit random forest on training data
fit_rf1 <- randomForest(CRED_APPROVED~. , data = train)
# Predict outcomes on test data
predict_rf <- predict(fit_rf1, newdata= test)
misClasificError <- mean(predict_rf != test$CRED_APPROVED)
print(paste('Accuracy',1-misClasificError))
# Confusion matrix
library(caret)
# http://dni-institute.in/blogs/random-forest-using-r-step-by-step-tutorial/
# install.packages("boot")
# Remember to change the working directory to the appropriate place on your computer- where ever the data is located
# on the top line (where file, edit ...) - go to session -> set working directory -> choose directory
# Then change this line with the appropriate one
setwd("C:/Users/board/Desktop/Kaggle/mf850_extra")
data <- read.csv("mf850-loan-data.csv")
# Data cleaning - change variables into categorical variables
data$DEPENDENTS <- as.factor(data$DEPENDENTS)
data$CRED_HERE <- as.factor(data$CRED_HERE)
data$INSTALLMENTRATE <- as.factor(data$INSTALLMENTRATE)
data$ATADDRESSSINCE <- as.factor(data$ATADDRESSSINCE)
# Scale continous variables
data$AGE <- scale(data$AGE)
data$DURATION <- scale(data$DURATION)
# Splitting the data into test/ train sets
# https://ragrawal.wordpress.com/2012/01/14/dividing-data-into-training-and-testing-dataset-in-r/
# Sample split into test train set
indexes <- sample(1:nrow(data), size = 0.2*nrow(data))
test <- data[indexes, ]
train <- data[-indexes, ]
# Baseline of only guessing yes
(sum(data$CRED_APPROVED == 'YES')/ length(data$CRED_APPROVED))
table(data$CRED_APPROVED)/nrow(data)
# Fit logistic regression using all of the data
fit1 <- glm(CRED_APPROVED~. , family = "binomial", data = data)
summary(fit1)
# Library for computing cross validation with logistic regression models
library(boot) # cv.glm function
# cv.glm computes cross validation error rate
cv_est <- cv.glm(data, fit1, K=10)$delta[1]
(fit1_cv <- 1-cv_est)
# Fit logisitic regression on test set
fit2 <- glm(CRED_APPROVED~. , family = "binomial", data=test)
# Predict ratios on test set
predict_fit2 <- predict(fit2, newdata=test, type = "response")
hist(predict_fit2, breaks= 20)
# Use 50% threshold for predictions ( we can try different thresholds later )
results2  <- ifelse(predict_fit2 > 0.5,'YES','NO')
# Compare with the original results
misClasificError <- mean(results2 != test$CRED_APPROVED)
print(paste('Accuracy',1-misClasificError))
# Confusion matrix
table(test$CRED_APPROVED, predict_fit2>0.5)
predict_fit2
summary(predict_fit2)
# install.packages("boot")
# Remember to change the working directory to the appropriate place on your computer- where ever the data is located
# on the top line (where file, edit ...) - go to session -> set working directory -> choose directory
# Then change this line with the appropriate one
setwd("C:/Users/board/Desktop/Kaggle/mf850_extra")
data <- read.csv("mf850-loan-data.csv")
# Data cleaning - change variables into categorical variables
data$DEPENDENTS <- as.factor(data$DEPENDENTS)
data$CRED_HERE <- as.factor(data$CRED_HERE)
data$INSTALLMENTRATE <- as.factor(data$INSTALLMENTRATE)
data$ATADDRESSSINCE <- as.factor(data$ATADDRESSSINCE)
# Scale continous variables
data$AGE <- scale(data$AGE)
data$DURATION <- scale(data$DURATION)
# Splitting the data into test/ train sets
# https://ragrawal.wordpress.com/2012/01/14/dividing-data-into-training-and-testing-dataset-in-r/
# Sample split into test train set
indexes <- sample(1:nrow(data), size = 0.2*nrow(data))
test <- data[indexes, ]
train <- data[-indexes, ]
# Baseline of only guessing yes
(sum(data$CRED_APPROVED == 'YES')/ length(data$CRED_APPROVED))
table(data$CRED_APPROVED)/nrow(data)
# Fit logistic regression using all of the data
fit1 <- glm(CRED_APPROVED~. , family = "binomial", data = data)
summary(fit1)
# Library for computing cross validation with logistic regression models
library(boot) # cv.glm function
# cv.glm computes cross validation error rate
cv_est <- cv.glm(data, fit1, K=10)$delta[1]
(fit1_cv <- 1-cv_est)
# Fit logisitic regression on test set
fit2 <- glm(CRED_APPROVED~. , family = "binomial", data=test)
# Predict ratios on test set
predict_fit2 <- predict(fit2, newdata=test, type = "response")
hist(predict_fit2, breaks= 20)
# Use 50% threshold for predictions ( we can try different thresholds later )
results2  <- ifelse(predict_fit2 > 0.5,'YES','NO')
# Compare with the original results
misClasificError <- mean(results2 != test$CRED_APPROVED)
print(paste('Accuracy',1-misClasificError))
# Confusion matrix
table(test$CRED_APPROVED, predict_fit2>0.5)
# Lasso attempt
setwd("C:/Users/board/Desktop/Kaggle/mf850_extra")
data <- read.csv("mf850-loan-data.csv")
set.seed(1)
# Data cleaning - change variables into categorical variables
data$DEPENDENTS <- as.factor(data$DEPENDENTS)
data$CRED_HERE <- as.factor(data$CRED_HERE)
data$INSTALLMENTRATE <- as.factor(data$INSTALLMENTRATE)
data$ATADDRESSSINCE <- as.factor(data$ATADDRESSSINCE)
# Scale continous variables
data$AGE <- scale(data$AGE)
data$DURATION <- scale(data$DURATION)
# Splitting the data into test/ train sets
# https://ragrawal.wordpress.com/2012/01/14/dividing-data-into-training-and-testing-dataset-in-r/
# Sample split into test train set
indexes <- sample(1:nrow(data), size = 0.2*nrow(data))
test <- data[indexes, ]
train <- data[-indexes, ]
library(glmnet) # glmnet for ridge/ lasso regression
# Split train data into independent and dependent variables
# model matrix splits data into dummy variables
x = model.matrix(CRED_APPROVED~., data = train)
y = ifelse(train$CRED_APPROVED== 'YES',1,0)
# Use cross validation with to determine the lambda parameter for lasso regression
lambdas <- 10^seq(3,-5, length = 100)
cv.lasso = cv.glmnet(x, y, family = "binomial", lambda = lambdas, alpha = 1, standardize = FALSE)
# Plot lambda vs. cross validation error mean
lasso_lambdas <- cv.lasso$lambda
lasso_cv_means <- cv.lasso$cvm
plot(lasso_lambdas, lasso_cv_means, main = "Lasso Lambda vs Cross Validation Error mean")
# should the lambda with the lowest cross validation error rate
(bestlam = cv.lasso$lambda.min)
# look at coefficients which are not 0 of lasso regression
lasso1 <- glmnet(x, y, family = "binomial", alpha = 1, standardize = FALSE, lambda = lasso_lambdas)
lasso.coef <- predict(lasso1, type = "coefficients", s= bestlam)[1:(ncol(x)) ,]
lasso.coef
lasso.coef[lasso.coef!=0]
length(lasso.coef[lasso.coef!=0])
test1 <- model.matrix(CRED_APPROVED~., family = "binomial", data=test)
predict1 <- predict(lasso1, newx= test1, type = "response", s= bestlam)
hist(predict1, breaks= 20)
results2  <- ifelse(predict1 > 0.5,'YES','NO')
# Compare with the original results
misClasificError <- mean(results2 != test$CRED_APPROVED)
print(paste('Accuracy',1-misClasificError))
# Confusion matrix
table(test$CRED_APPROVED, predict1>0.5)
# Split categorical variables into seperate columns
x = model.matrix(CRED_APPROVED~., data = train)
# Re structure data so the data so it is a data frame and not a matrix
data3 <- data.frame(x)
# Save names of the coefficients in the backward step wise regression
coef_names <- names(lasso.coef)
# Delete the first name which is X intercept
coef_names <- coef_names[-1]
# Make sure all the variables are in the data set
data_col_names <- colnames(data3)
sum(coef_names%in% data_col_names) == (length(coef_names))
# Get the columns from the new data set
test_rf <- data3[,coef_names]
# new_log <- glm(CRED_APPROVED~., family = "binomial", data = data_rf)
coef_names <- names(lasso.coef)
coef_names <- coef_names[-2]
coef_names <- names(lasso.coef)
# Delete the first name which is X intercept
coef_names <- coef_names[c(-1,-2)]
# Make sure all the variables are in the data set
data_col_names <- colnames(data3)
sum(coef_names%in% data_col_names) == (length(coef_names))
# Get the columns from the new data set
test_rf <- data3[,coef_names]
# new_log <- glm(CRED_APPROVED~., family = "binomial", data = data_rf)
# Lasso attempt
setwd("C:/Users/board/Desktop/Kaggle/mf850_extra")
data <- read.csv("mf850-loan-data.csv")
set.seed(1)
# Data cleaning - change variables into categorical variables
data$DEPENDENTS <- as.factor(data$DEPENDENTS)
data$CRED_HERE <- as.factor(data$CRED_HERE)
data$INSTALLMENTRATE <- as.factor(data$INSTALLMENTRATE)
data$ATADDRESSSINCE <- as.factor(data$ATADDRESSSINCE)
# Scale continous variables
data$AGE <- scale(data$AGE)
data$DURATION <- scale(data$DURATION)
# Splitting the data into test/ train sets
# https://ragrawal.wordpress.com/2012/01/14/dividing-data-into-training-and-testing-dataset-in-r/
# Sample split into test train set
indexes <- sample(1:nrow(data), size = 0.2*nrow(data))
test <- data[indexes, ]
train <- data[-indexes, ]
library(glmnet) # glmnet for ridge/ lasso regression
# Split train data into independent and dependent variables
# model matrix splits data into dummy variables
x = model.matrix(CRED_APPROVED~., data = train)
y = ifelse(train$CRED_APPROVED== 'YES',1,0)
# Use cross validation with to determine the lambda parameter for lasso regression
lambdas <- 10^seq(3,-5, length = 100)
cv.lasso = cv.glmnet(x, y, family = "binomial", lambda = lambdas, alpha = 1, standardize = FALSE)
# Plot lambda vs. cross validation error mean
lasso_lambdas <- cv.lasso$lambda
lasso_cv_means <- cv.lasso$cvm
plot(lasso_lambdas, lasso_cv_means, main = "Lasso Lambda vs Cross Validation Error mean")
# should the lambda with the lowest cross validation error rate
(bestlam = cv.lasso$lambda.min)
# look at coefficients which are not 0 of lasso regression
lasso1 <- glmnet(x, y, family = "binomial", alpha = 1, standardize = FALSE, lambda = lasso_lambdas)
lasso.coef <- predict(lasso1, type = "coefficients", s= bestlam)[1:(ncol(x)) ,]
lasso.coef
lasso.coef[lasso.coef!=0]
length(lasso.coef[lasso.coef!=0])
test1 <- model.matrix(CRED_APPROVED~., family = "binomial", data=test)
predict1 <- predict(lasso1, newx= test1, type = "response", s= bestlam)
hist(predict1, breaks= 20)
results2  <- ifelse(predict1 > 0.5,'YES','NO')
# Compare with the original results
misClasificError <- mean(results2 != test$CRED_APPROVED)
print(paste('Accuracy',1-misClasificError))
# Confusion matrix
table(test$CRED_APPROVED, predict1>0.5)
# Split categorical variables into seperate columns
x = model.matrix(CRED_APPROVED~., data = train)
# Re structure data so the data so it is a data frame and not a matrix
data3 <- data.frame(x)
# Save names of the coefficients in the backward step wise regression
coef_names <- names(lasso.coef)
# Delete the first name which is X intercept
coef_names <- coef_names[c(-1,-2)]
# Make sure all the variables are in the data set
data_col_names <- colnames(data3)
sum(coef_names%in% data_col_names) == (length(coef_names))
# Get the columns from the new data set
test_rf <- data3[,coef_names]
# new_log <- glm(CRED_APPROVED~., family = "binomial", data = data_rf)
# Ridge
# Ridge attempt
setwd("C:/Users/board/Desktop/Kaggle/mf850_extra")
data <- read.csv("mf850-loan-data.csv")
set.seed(1)
# Data cleaning - change variables into categorical variables
data$DEPENDENTS <- as.factor(data$DEPENDENTS)
data$CRED_HERE <- as.factor(data$CRED_HERE)
data$INSTALLMENTRATE <- as.factor(data$INSTALLMENTRATE)
data$ATADDRESSSINCE <- as.factor(data$ATADDRESSSINCE)
# Scale continous variables
data$AGE <- scale(data$AGE)
data$DURATION <- scale(data$DURATION)
# Splitting the data into test/ train sets
# https://ragrawal.wordpress.com/2012/01/14/dividing-data-into-training-and-testing-dataset-in-r/
# Sample split into test train set
indexes <- sample(1:nrow(data), size = 0.2*nrow(data))
test <- data[indexes, ]
train <- data[-indexes, ]
library(glmnet) # glmnet for ridge/ ridge regression
# Split train data into independent and dependent variables
# model matrix splits data into dummy variables
x = model.matrix(CRED_APPROVED~., family = "binomial", data = train)
y = ifelse(train$CRED_APPROVED == 'YES',1,0)
# Use cross validation with to determine the lambda parameter for ridge regression
lambdas <- 10^seq(4,-5, length = 100)
cv.ridge = cv.glmnet(x, y, family = "binomial", lambda = lambdas, alpha = 0, standardize = FALSE)
# Plot lambda vs. cross validation error mean
ridge_lambdas <- cv.ridge$lambda
ridge_cv_means <- cv.ridge$cvm
plot(ridge_lambdas, ridge_cv_means, main = "ridge Lambda vs Cross Validation Error mean")
# should the lambda with the lowest cross validation error rate
bestlam = cv.ridge$lambda.min
# look at coefficients which are not 0 of ridge regression
ridge1 <- glmnet(x, y, family = "binomial", alpha = 0, standardize = FALSE, lambda = lambdas)
ridge.coef <- predict(ridge1, type = "coefficients", s= bestlam)[1:(ncol(x)) ,]
ridge.coef
ridge.coef[abs(ridge.coef) > 0.001]
length(ridge.coef[abs(ridge.coef) > 0.1])
test1 <- model.matrix(CRED_APPROVED~., family = "binomial", data=test)
predict1 <- predict(ridge1, newx= test1, type = "response", s= bestlam)
hist(predict1, breaks= 20)
results2  <- ifelse(predict1 > 0.5,'YES','NO')
# Compare with the original results
misClasificError <- mean(results2 != test$CRED_APPROVED)
print(paste('Accuracy',1-misClasificError))
# Confusion matrix
table(test$CRED_APPROVED, predict1>0.5)
ntree_df <- df(matrix(0, times= 50*4))
?data.frame
?matrix
ntree_df <- df(matrix(0, time= 50*4))
ntree_df <- df(0, times =2)
ntree_df <- df(matrix(0, nrow= 50, ncol = 4))
ntree_df <- data.frame(matrix(0, nrow= 50, ncol = 4))
View(ntree_df)
View(ntree_df)
names(fit_rf2)
# Stepwise Variable selection
setwd("C:/Users/board/Desktop/Kaggle/mf850_extra")
data <- read.csv("mf850-loan-data.csv")
set.seed(1)
# Data cleaning - change variables into categorical variables
data$DEPENDENTS <- as.factor(data$DEPENDENTS)
data$CRED_HERE <- as.factor(data$CRED_HERE)
data$INSTALLMENTRATE <- as.factor(data$INSTALLMENTRATE)
data$ATADDRESSSINCE <- as.factor(data$ATADDRESSSINCE)
# Scale continous variables
data$AGE <- scale(data$AGE)
data$DURATION <- scale(data$DURATION)
# Splitting the data into test/ train sets
# https://ragrawal.wordpress.com/2012/01/14/dividing-data-into-training-and-testing-dataset-in-r/
# Sample split into test train set
indexes <- sample(1:nrow(data), size = 0.2*nrow(data))
test <- data[indexes, ]
train <- data[-indexes, ]
# Try backwards stepwise regression with logistic regression
# Inspiration
# http://www.utstat.toronto.edu/~brunner/oldclass/appliedf11/handouts/2101f11StepwiseLogisticR.pdf
# Logistic regression with all variables
fullmod <- glm(CRED_APPROVED~. , family = "binomial", data =train)
summary(fullmod)
# Logisitic regression with no variables
nothing <- glm(CRED_APPROVED~1, family = "binomial", data = train)
summary(nothing) # Essentially intercept says yes (it is greater than 0.5)
# Backward stepwise regression
backwards <- step(fullmod, direction = "backward", trace = 0)
summary(backwards)
length(backwards$coefficients)
# Great only 35 variables compared to 56
# Let's see how it does on the prediction set
predict_fit2 <- predict(backwards, newdata=test, type = "response")
hist(predict_fit2, breaks = 20)
# Use 50% threshold for predictions ( we can try different thresholds later )
results2  <- ifelse(predict_fit2 > 0.5,'YES','NO')
# Compare with the original results
misClasificError <- mean(results2 != test$CRED_APPROVED)
print(paste('Accuracy',1-misClasificError))
# Get the variables from backward selection
# Split categorical variables into seperate columns
x = model.matrix(CRED_APPROVED~., data = train)
# Re structure data so the data so it is a data frame and not a matrix
data3 <- data.frame(x)
# Save names of the coefficients in the backward step wise regression
coef_names <- names(backwards$coefficients)
# Delete the first name which is X intercept
coef_names <- coef_names[-1]
# Make sure all the variables are in the data set
data_col_names <- colnames(data3)
sum(coef_names%in% data_col_names) == (length(coef_names))
# Get the columns from the new data set
data_rf <- data3[,coef_names]
data1 <- cbind(data_rf, y)
# Random forest with that data
library(randomForest)
fit_rf2 <- randomForest(as.factor(y)~. , data = data1)
fit_rf2
importance(fit_rf2)
names(fit_rf2)
fit_rf2[4]
fit_rf2[5]
# Create data frame to store ntree solving results
ntree_df <- data.frame(matrix(0, nrow= 50, ncol = 4))
for (ntree_times in 1:15){
ntree <- 500+ntree_times*10
fit_temp <- randomForest(as.factor(y~., data= data1, ntree = ntree))
ntree_df[ntree_time,] <- fit_temp[5]
ntree_df[ntree_time, 4] <- ntree
}
?randomForest
for (ntree_times in 1:15){
ntree <- 500+ntree_times*10
fit_temp <- randomForest(as.factor(y)~., data= data1, ntree = ntree))
ntree_df[ntree_time,] <- fit_temp[5]
ntree_df[ntree_time, 4] <- ntree
}
for (ntree_times in 1:15){
ntree <- 500+ntree_times*10
fit_temp <- randomForest(as.factor(y)~., data= data1, ntree = ntree)
ntree_df[ntree_time,] <- fit_temp[5]
ntree_df[ntree_time, 4] <- ntree
}
for (ntree_times in 1:15){
ntree <- 500+ntree_times*10
fit_temp <- randomForest(as.factor(y)~., data= data1, ntree = ntree)
ntree_df[ntree_times,] <- fit_temp[5]
ntree_df[ntree_times, 4] <- ntree
}
